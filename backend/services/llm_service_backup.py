#!/usr/bin/env python3
"""
ServiÃ§o LLM - IntegraÃ§Ã£o com Google Gemini
Chat inteligente e geraÃ§Ã£o de insights automÃ¡ticos
"""

import os
import json
import asyncio
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
import google.generativeai as genai

logger = logging.getLogger(__name__)

class LLMService:
    """ServiÃ§o de integraÃ§Ã£o com Google Gemini LLM"""
    
    def __init__(self):
        """Inicializa o serviÃ§o Gemini"""
        self.api_key = os.getenv('GEMINI_API_KEY')
        if self.api_key:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash')
            self.enabled = True
            print("âœ… Gemini LLM configurado com sucesso")
        else:
            print("âš ï¸ GEMINI_API_KEY nÃ£o configurada, usando respostas mock")
            self.enabled = False
    
    def _get_dashboard_context(self, dashboard_data: Dict[str, Any]) -> str:
        """Cria contexto dos dados do dashboard para o LLM"""
        context = f"""
VocÃª Ã© um assistente especialista em anÃ¡lise de dados de mobilidade urbana.
Use os dados abaixo para responder perguntas e gerar insights:

ğŸ“Š DADOS ATUAIS DO DASHBOARD:
"""
        
        if 'metricas_principais' in dashboard_data:
            metrics = dashboard_data['metricas_principais']
            context += f"""
â€¢ Total de Corridas: {metrics.get('total_corridas', 0)}
â€¢ Corridas ConcluÃ­das: {metrics.get('corridas_concluidas', 0)}
â€¢ Corridas Canceladas: {metrics.get('corridas_canceladas', 0)}
â€¢ Receita Total: R$ {metrics.get('receita_total', 0):,.2f}
â€¢ Motoristas Ativos: {metrics.get('motoristas_ativos', 0)}
â€¢ AvaliaÃ§Ã£o MÃ©dia: {metrics.get('avaliacao_media', 0):.1f}/5
â€¢ Taxa de ConversÃ£o: {metrics.get('taxa_conversao', 0)}%
"""
        
        context += """
ğŸ¯ INSTRUÃ‡Ã•ES:
- Responda sempre em portuguÃªs brasileiro
- Use emojis para deixar as respostas mais visuais
- Seja conciso e direto
- ForneÃ§a insights acionÃ¡veis
- Use formataÃ§Ã£o markdown quando apropriado
"""
        return context
    
    def _get_system_prompts(self) -> Dict[str, str]:
        """Prompts do sistema para diferentes tipos de consulta"""
        return {
            'chat': """VocÃª Ã© um assistente especialista em anÃ¡lise de dados de mobilidade urbana. 
            Responda de forma clara, objetiva e sempre forneÃ§a insights Ãºteis baseados nos dados disponÃ­veis.""",
            
            'insights': """Analise os dados e gere insights automÃ¡ticos. 
            Identifique tendÃªncias, oportunidades de melhoria e possÃ­veis problemas. 
            Seja especÃ­fico e acionÃ¡vel.""",
            
            'report': """Gere um relatÃ³rio executivo baseado nos dados. 
            Use linguagem formal mas acessÃ­vel. 
            Inclua introduÃ§Ã£o, principais mÃ©tricas, anÃ¡lises e recomendaÃ§Ãµes."""
        }
    
    def chat_sync(self, question: str, context: dict = None) -> str:
        """VersÃ£o sÃ­ncrona do chat com LLM"""
        try:
            if context:
                return asyncio.run(self.chat(question, context))
            else:
                return asyncio.run(self.chat(question))
        except Exception as e:
            logger.error(f"Erro no chat sÃ­ncrono: {str(e)}")
            return "OlÃ¡! Sou o assistente de IA do dashboard. Como posso ajudÃ¡-lo a analisar os dados de mobilidade urbana?"

    async def chat(self, question: str, context: dict = None) -> str:
        """Processa pergunta do chat com contexto do dashboard"""
        if not self.enabled:
            return self._mock_chat_response(question)
        
        try:
            # Usar o contexto fornecido ou um contexto bÃ¡sico
            if context:
                context_text = self._get_dashboard_context(context)
            else:
                context_text = "Contexto: Dashboard de Mobilidade Urbana - Sistema de gestÃ£o de corridas de transporte."
            
            # Prompt mais conversacional e inteligente
            prompt = f"""VocÃª Ã© um assistente especialista em mobilidade urbana, amigÃ¡vel e conversacional.

{context_text}

ğŸ¯ INSTRUÃ‡Ã•ES:
- Seja natural e conversacional, nÃ£o robÃ³tico
- Identifique se Ã© uma saudaÃ§Ã£o, confirmaÃ§Ã£o, pergunta especÃ­fica ou conversa casual
- Para saudaÃ§Ãµes simples (oi, olÃ¡), responda de forma amigÃ¡vel e se apresente
- Para confirmaÃ§Ãµes (ok, blz), seja positivo e ofereÃ§a ajuda
- Para perguntas especÃ­ficas, use os dados fornecidos para anÃ¡lises detalhadas
- Sempre seja Ãºtil e proativo
- Use emojis moderadamente para deixar a conversa mais amigÃ¡vel

ğŸ‘¤ USUÃRIO: {question}

ğŸ¤– RESPOSTA NATURAL:"""
            
            response = self.model.generate_content(prompt)
            
            return {
                'success': True,
                'response': response.text,
                'timestamp': datetime.now().isoformat(),
                'type': 'chat'
            }
            
        except Exception as e:
            print(f"Erro no chat LLM: {e}")
            return {
                'success': False,
                'error': str(e),
                'response': "Desculpe, houve um erro ao processar sua mensagem. Tente novamente."
            }
    
    def generate_insights_sync(self, dashboard_data: dict) -> dict:
        """VersÃ£o sÃ­ncrona de generate_insights"""
        try:
            return asyncio.run(self.generate_insights(dashboard_data))
        except Exception as e:
            logger.error(f"Erro ao gerar insights sÃ­ncronos: {str(e)}")
            return {
                'success': True,
                'insights': self._mock_insights_response()['insights'],
                'timestamp': datetime.now().isoformat()
            }

    async def generate_insights(self, dashboard_data: dict) -> dict:
        """Gera insights automÃ¡ticos baseados nos dados"""
        if not self.enabled:
            return self._mock_insights_response()
        
        try:
            context = self._get_dashboard_context(dashboard_data)
            prompt = f"""{context}

ğŸ¯ TAREFA: Analise os dados acima e gere 3-5 insights importantes sobre:
1. Performance atual do negÃ³cio
2. Oportunidades de melhoria
3. PossÃ­veis problemas ou alertas
4. TendÃªncias identificadas

Formato a resposta em markdown com emojis."""
            
            response = self.model.generate_content(prompt)
            
            return {
                'success': True,
                'insights': response.text,
                'timestamp': datetime.now().isoformat(),
                'type': 'insights'
            }
            
        except Exception as e:
            print(f"Erro ao gerar insights: {e}")
            return {
                'success': False,
                'error': str(e),
                'insights': "NÃ£o foi possÃ­vel gerar insights no momento."
            }
    
    def generate_report_sync(self, dashboard_data: dict, report_type: str = "executive") -> dict:
        """VersÃ£o sÃ­ncrona de generate_report"""
        try:
            return asyncio.run(self.generate_report(dashboard_data, report_type))
        except Exception as e:
            logger.error(f"Erro ao gerar relatÃ³rio sÃ­ncrono: {str(e)}")
            return {
                'success': True,
                'report': self._mock_report_response()['report'],
                'timestamp': datetime.now().isoformat()
            }

    async def generate_report(self, dashboard_data: dict, report_type: str = "executive") -> dict:
        """Gera relatÃ³rio narrativo automÃ¡tico"""
        if not self.enabled:
            return self._mock_report_response()
        
        try:
            context = self._get_dashboard_context(dashboard_data)
            prompt = f"""{context}

ğŸ¯ TAREFA: Gere um relatÃ³rio {report_type} completo baseado nos dados.

ESTRUTURA DO RELATÃ“RIO:
1. **Resumo Executivo** - Principais destaques
2. **MÃ©tricas Principais** - AnÃ¡lise detalhada dos nÃºmeros
3. **TendÃªncias Identificadas** - PadrÃµes e mudanÃ§as
4. **Oportunidades** - Ãreas de melhoria
5. **RecomendaÃ§Ãµes** - AÃ§Ãµes especÃ­ficas

Use linguagem profissional, formataÃ§Ã£o markdown e emojis apropriados."""
            
            response = self.model.generate_content(prompt)
            
            return {
                'success': True,
                'report': response.text,
                'report_type': report_type,
                'timestamp': datetime.now().isoformat(),
                'type': 'report'
            }
            
        except Exception as e:
            print(f"Erro ao gerar relatÃ³rio: {e}")
            return {
                'success': False,
                'error': str(e),
                'report': "NÃ£o foi possÃ­vel gerar o relatÃ³rio no momento."
            }
    
    def _mock_chat_response(self, question: str) -> Dict[str, Any]:
        """Resposta mock inteligente e conversacional"""
        question_lower = question.lower().strip()
        
        # SaudaÃ§Ãµes e cumprimentos
        saudacoes = ['oi', 'olÃ¡', 'ola', 'hello', 'hi', 'hey', 'e aÃ­', 'e ai', 'bom dia', 'boa tarde', 'boa noite']
        confirmacoes = ['ok', 'blz', 'beleza', 'certo', 'entendi', 'perfeito', 'legal', 'show', 'tranquilo', 'valeu', 'obrigado', 'obrigada', 'tÃ¡ bom', 'ta bom']
        
        if any(saud in question_lower for saud in saudacoes):
            response = "ğŸ‘‹ OlÃ¡! Fico feliz em conversar com vocÃª! Sou especialista em anÃ¡lise de dados de mobilidade urbana. VocÃª gostaria de saber algo especÃ­fico sobre as mÃ©tricas do dashboard ou tem alguma dÃºvida sobre o sistema?"
            
        elif any(conf in question_lower for conf in confirmacoes):
            response = "âœ… Perfeito! Se precisar de qualquer anÃ¡lise dos dados ou tiver dÃºvidas sobre mobilidade urbana, estarei aqui para ajudar. VocÃª pode me perguntar sobre corridas, receita, motoristas ou qualquer mÃ©trica do sistema!"
            
        elif any(word in question_lower for word in ['tchau', 'atÃ© logo', 'ate logo', 'atÃ© mais', 'ate mais', 'bye']):
            response = "ï¿½ AtÃ© logo! Foi um prazer ajudar. Volte sempre que precisar analisar os dados de mobilidade urbana!"
            
        # Perguntas especÃ­ficas sobre dados
        elif any(word in question_lower for word in ['corrida', 'viagem', 'trajeto']):
            response = "ğŸš— Sobre as corridas: atualmente temos 0 corridas registradas. Para obter insights valiosos, recomendo importar dados histÃ³ricos ou registrar algumas corridas no sistema. Posso ajudar a analisar padrÃµes de demanda, rotas mais utilizadas e performance dos motoristas!"
            
        elif any(word in question_lower for word in ['receita', 'dinheiro', 'faturamento', 'ganho', 'lucro']):
            response = "ğŸ’° AnÃ¡lise financeira: A receita atual estÃ¡ em R$ 0,00. Para aumentar o faturamento, sugiro focar em: 1) Aumentar o nÃºmero de corridas concluÃ­das, 2) Otimizar preÃ§os por zona/horÃ¡rio, 3) Reduzir cancelamentos. Quer que eu analise estratÃ©gias especÃ­ficas?"
            
        elif any(word in question_lower for word in ['motorista', 'driver', 'condutor']):
            response = "ğŸ‘¥ GestÃ£o de motoristas: NÃ£o hÃ¡ motoristas ativos no momento. Para construir uma base sÃ³lida, recomendo: 1) Programa de recrutamento, 2) Incentivos para novos cadastros, 3) Treinamento sobre o app. Meta inicial: 10-20 motoristas ativos!"
            
        elif any(word in question_lower for word in ['ajuda', 'help', 'socorro', 'nÃ£o sei', 'nao sei']):
            response = "ğŸ†˜ Claro! Posso te ajudar com: \nâ€¢ ğŸ“Š **AnÃ¡lise de dados** - mÃ©tricas, KPIs, performance\nâ€¢ ğŸš— **GestÃ£o de corridas** - padrÃµes, otimizaÃ§Ã£o\nâ€¢ ğŸ‘¥ **Motoristas** - recrutamento, retenÃ§Ã£o\nâ€¢ ğŸ’° **Receita** - estratÃ©gias de crescimento\nâ€¢ ğŸ“ˆ **RelatÃ³rios** - insights automÃ¡ticos\n\nO que vocÃª gostaria de saber?"
            
        elif '?' in question or any(word in question_lower for word in ['como', 'quando', 'onde', 'por que', 'porque', 'qual', 'quanto']):
            # Pergunta real detectada
            response = f"ğŸ¤” Interessante pergunta sobre '{question}'. Com os dados atuais ainda zerados, posso te dar orientaÃ§Ãµes gerais sobre mobilidade urbana. Para anÃ¡lises mais especÃ­ficas e precisas, seria ideal ter alguns dados histÃ³ricos no sistema. Quer que eu te explique como interpretar alguma mÃ©trica especÃ­fica?"
            
        else:
            # Conversa casual ou nÃ£o identificada
            response = "ğŸ’¬ Entendi! Estou aqui para conversar sobre mobilidade urbana e analisar dados do dashboard. VocÃª tem alguma dÃºvida especÃ­fica sobre as mÃ©tricas, quer discutir estratÃ©gias de crescimento ou precisa de ajuda com alguma funcionalidade?"
        
        return {
            'success': True,
            'response': response,
            'timestamp': datetime.now().isoformat(),
            'type': 'chat',
            'mock': True
        }
    
    def _mock_insights_response(self) -> Dict[str, Any]:
        """Insights mock para desenvolvimento"""
        insights = """
## ğŸ” **Insights AutomÃ¡ticos**

### ğŸ“Š **Status Atual**
- **Sistema em fase inicial** - Dados zerados indicam inÃ­cio de operaÃ§Ã£o
- **Oportunidade de crescimento** - Base limpa para implementar estratÃ©gias

### ğŸ¯ **RecomendaÃ§Ãµes Imediatas**
1. **ğŸš€ Importar dados histÃ³ricos** para anÃ¡lises mais precisas
2. **ğŸ‘¥ Recrutar motoristas** - Meta inicial: 10-20 motoristas ativos  
3. **ğŸ“± LanÃ§ar campanha** para atrair primeiros usuÃ¡rios
4. **ğŸ“Š Configurar mÃ©tricas** de acompanhamento diÃ¡rio

### âš¡ **PrÃ³ximos Passos**
- Implementar sistema de importaÃ§Ã£o de dados
- Criar dashboards de acompanhamento
- Definir KPIs de crescimento
"""
        
        return {
            'success': True,
            'insights': insights,
            'timestamp': datetime.now().isoformat(),
            'type': 'insights',
            'mock': True
        }
    
    def _mock_report_response(self) -> Dict[str, Any]:
        """RelatÃ³rio mock para desenvolvimento"""
        report = """
# ğŸ“‹ **RelatÃ³rio Executivo - Dashboard de Mobilidade**

## ğŸ“Š **Resumo Executivo**
O dashboard estÃ¡ em fase inicial de operaÃ§Ã£o, com estrutura completa implementada e pronta para receber dados. Sistema 100% funcional aguardando inÃ­cio das operaÃ§Ãµes.

## ğŸ“ˆ **MÃ©tricas Principais**
- **Total de Corridas**: 0 (base limpa)
- **Receita**: R$ 0,00 (prÃ©-operaÃ§Ã£o)
- **Motoristas Ativos**: 0 (fase de recrutamento)
- **Status do Sistema**: âœ… Operacional

## ğŸ¯ **Oportunidades Identificadas**
1. **Mercado Virgem**: Oportunidade de ser pioneiro na regiÃ£o
2. **Tecnologia AvanÃ§ada**: Dashboard moderno com IA integrada
3. **Escalabilidade**: Infraestrutura preparada para crescimento

## ğŸ’¡ **RecomendaÃ§Ãµes EstratÃ©gicas**
1. **Fase 1**: Recrutar 20 motoristas nos prÃ³ximos 30 dias
2. **Fase 2**: LanÃ§ar campanha de marketing para usuÃ¡rios
3. **Fase 3**: Implementar sistema de referÃªncia/gamificaÃ§Ã£o

---
*RelatÃ³rio gerado automaticamente em {datetime.now().strftime('%d/%m/%Y Ã s %H:%M')}*
"""
        
        return {
            'success': True,
            'report': report,
            'report_type': 'executive',
            'timestamp': datetime.now().isoformat(),
            'type': 'report',
            'mock': True
        }

# InstÃ¢ncia global do serviÃ§o LLM
llm_service = LLMService()
